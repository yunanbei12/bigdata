用户查询日志的存储与处理
数据来源：sohu用户搜索日志数据（一天），https://www.sogou.com/labs/resource/q.php
系统要求：基于Hadoop，HBASE和SPARK实现，语言使用JAVA SCALA或PYTHON皆可
数据格式：访问时间\t用户ID\t[查询词]\t该URL在返回结果中的排名\t用户点击的顺序号\t用户点击的URL (其中\t为制表符)
系统要求：
一、数据清洗部分
实现一个程序，载入文本中的日志数据，每行作为一条记录，分为访问时间，用户ID，查询词，返回结果排名，顺序号，URL这六个字段（列），存入以下两种数据源(均需要实现)：
（1）HBASE。（2）MongoDB

二、数据搜索与统计部分：
1.使用HBASE与MongoDB的原生API实现条件查询功能，例如：“访问时间在1点到2点之间且URL属于百度的网页”等，即能够支持根据六个字段的一个或多个字段内容，使用不同条件（关键字或数值范围）进行联合搜索。
（1）根据开始时间和结束时间搜索这段时间内的访问记录。输入信息为开始时间和结束时间，用‘|’字符隔开）
（2）根据用户ID搜索该用户的访问记录。输入信息为一个或多个用户ID，用‘|’字符隔开 （输入多个用户ID时，要求记录匹配其中任意一个用户的均满足条件）。
（3）根据关键字搜索含有该关键字的用户查询词记录。输入信息为一个或多个关键字，用‘|’字符隔开 （输入多个关键字时，要求记录匹配其中任意一个关键字的均满足条件）。
（4）根据关键字（如baidu）等搜索相关网站的URL访问记录，输入信息为一个或多个关键字，用‘|’字符隔开 （输入多个关键字时，要求记录匹配其中任意一个关键字的均满足条件）。
（5）实现以上四个条件任意组合的联合搜索。四个条件之间用’+’字符隔开 （联合搜索要求所有条件同时满足）
要求有条件输入界面，用命令行或UI界面均可。
2. 使用Hadoop Mapreduce或SPARK的RDD，实现以下功能：
基于大数据计算技术的条件查询：使用mapreduce框架或RDD算子转换操作或Spark SQL功能，实现类似于题目1的六个字段条件搜索。
时段流量统计：以hh:mm:ss格式输入起始时间和结束时间，统计这段时间之内的总搜索次数、各个查询词搜索次数，各个网站的访问量。其中网站访问量为根据URL统计网站访问，属于同一个网站的URL算在同一个网站上，如women.sohu.com/20070508/n249762812.shtml，s.sohu.com/20080220/n255256097.shtml，peng.blog.sohu.com等不同的sohu网页都统计为sohu网站的访问次数。
用户使用频率统计：统计每个用户一天内的搜索次数
访问行为统计：根据该页面在搜索结果中的排名(第4字段)，统计不同排名的结果被访问的情况。如排名第一的结果被访问次数，排名第二的结果被访问次数……
提示：SPARK加载中文要注意使用UTF-8编码，否则可能出现乱码

三、搜索结果缓存模块部分
1.当搜索结果超出100条数量时，截取前100条并增加提示。
2.使用Redis，以搜索条件：搜索结果为键值对，将最近20条搜索结果（包括所有搜索类型，加起来20条）缓存在Redis中，每次搜索时，先查找缓冲区是否有对应的搜索结果，若有，直接读取，并将该缓存记录设置为最近1次的搜索；若没有，再执行搜索并缓存。当新结果缓存时，超出最近20次的旧记录应当从redis中移除。

四、日志系统
用户输入的任务起始与结束要能够以简要的信息形式记录在硬盘日志中，能够根据日志判断未完成的任务并重做。
